{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18efd93a-7414-4da1-b630-5e2b2103ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a) Import required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af3beae6-e5ec-44b9-8d51-415b39ff2577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pre-trained VGG16 model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Step 1: Load the Pre-trained CNN Model (VGG16 without top)\n",
    "# ==========================================================\n",
    "base_model = VGG16(weights='vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                   include_top=False,\n",
    "                   input_shape=(224, 224, 3))\n",
    "\n",
    "print(\"âœ… Pre-trained VGG16 model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7fad24e-5ed0-4542-8d6b-63e15b65b317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Base layers frozen.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Step 2: Freeze lower convolutional layers\n",
    "# ==========================================================\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(\"âœ… Base layers frozen.\")\n",
    "\n",
    "# ==========================================================\n",
    "# Step 3: Add custom classifier (fully connected layers)\n",
    "# ==========================================================\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(4, activation='softmax')  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45ca9fc-ff82-452a-bf55-025c6f64462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Step 4: Compile the model\n",
    "# ==========================================================\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61ce1684-23d4-454b-bac1-de7d45475646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 153 images belonging to 4 classes.\n",
      "Found 36 images belonging to 4 classes.\n",
      "âœ… Dataset loaded successfully.\n",
      "Number of classes: 4\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Step 5: Prepare the dataset (images in subfolders)\n",
    "# ==========================================================\n",
    "data_dir = \"dataset\"  # your dataset folder\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # 80% training, 20% validation\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "print(\"âœ… Dataset loaded successfully.\")\n",
    "\n",
    "\n",
    "print(\"Number of classes:\", train_generator.num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d723c6-81ae-4765-8c21-f70cefdd4584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UTKARSH BRAHMANKAR\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5s/step - accuracy: 0.3411 - loss: 1.4866 - val_accuracy: 0.7222 - val_loss: 0.7982\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4s/step - accuracy: 0.5564 - loss: 1.0206 - val_accuracy: 0.9167 - val_loss: 0.5238\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5s/step - accuracy: 0.7416 - loss: 0.7029 - val_accuracy: 0.9167 - val_loss: 0.3551\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5s/step - accuracy: 0.8419 - loss: 0.4806 - val_accuracy: 0.9722 - val_loss: 0.2197\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5s/step - accuracy: 0.9113 - loss: 0.3382 - val_accuracy: 0.9722 - val_loss: 0.1500\n",
      "ğŸ”„ Fine-tuning top layers...\n",
      "Epoch 1/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6s/step - accuracy: 0.9077 - loss: 0.2766 - val_accuracy: 0.9444 - val_loss: 0.1704\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6s/step - accuracy: 0.8784 - loss: 0.3453 - val_accuracy: 1.0000 - val_loss: 0.1003\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5s/step - accuracy: 0.9487 - loss: 0.2205 - val_accuracy: 0.9722 - val_loss: 0.0744\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6s/step - accuracy: 0.9329 - loss: 0.1944 - val_accuracy: 0.9444 - val_loss: 0.1066\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.9318 - loss: 0.1830 - val_accuracy: 1.0000 - val_loss: 0.0405\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Step 6: Train the classifier layers\n",
    "# ==========================================================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# Step 7: Fine-tune (unfreeze top layers)\n",
    "# ==========================================================\n",
    "# Unfreeze last 4 convolutional layers\n",
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Re-compile with smaller learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"ğŸ”„ Fine-tuning top layers...\")\n",
    "\n",
    "fine_tune_history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16089ff6-a18e-471b-87c8-db9e8eb13da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 527ms/step - accuracy: 1.0000 - loss: 0.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Final Validation Accuracy: 100.00%\n",
      "âœ… Model saved successfully as vgg16_transfer_learning_final.h5\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Step 8: Evaluate and Save the model\n",
    "# ==========================================================\n",
    "loss, acc = model.evaluate(val_generator)\n",
    "print(f\"\\nâœ… Final Validation Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "model.save(\"vgg16_transfer_learning_final.h5\")\n",
    "print(\"âœ… Model saved successfully as vgg16_transfer_learning_final.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7759a0-8b0d-4ac2-aae6-3b9a7fe9800c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c74befd-8517-4f1a-8f0f-aff0b66d2c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
